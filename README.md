![](https://drive.google.com/open?id=1yppQPZFGs7533IuwRFzOAaXAcUS7aQbq)

![](https://media.giphy.com/media/3oKIPEqDGUULpEU0aQ/giphy.gif)

### Automating the Build

Build a pipeline to automate the processing of raw data for discovery and modeling
Know the main steps to prepare data for modeling
Know how to handle the different data types in R
Understand data imputation
Treat categorical data properly with binarization (making dummy columns)
Apply feature engineering to dates, integers and real numbers
Apply variable selection, correlation and significance tests
Model and measure prepared data using both supervised and unsupervised modeling
Description

As a Data scientist facing constant repetitive task when approaching new datasets, this repo aims at automating a lot of these tasks in order to get to the actual analysis as quickly as possible. Of course, there will always be exceptions to the rule, some manual work and customization will be required. But overall a large swath of that work can be automated by building a smart pipeline. This is what I’ll do here. This is especially important in the era of big data where handling variables by hand isn’t always possible.

This is a great learning strategy to think in terms of an automated pipeline and to understand, design and build each stage as separate and independent units.


