{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "buildAPI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x08RJRA5spSq",
        "colab_type": "text"
      },
      "source": [
        "# Build an API for our Machine Learning Model\n",
        "## June 8, 2020 \n",
        "## About RIHAD VARIAWA\n",
        "> As a Data Scientist and former head of global fintech research at Malastare.ai, I find fulfillment tacking challenges to solve complex problems using data\n",
        "\n",
        "![](https://media.giphy.com/media/U4FkC2VqpeNRHjTDQ5/giphy.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLVINqzJj2if",
        "colab_type": "text"
      },
      "source": [
        "As a data scientist, I want to make impact with my machine learning models. However, this is easier said than done. When starting a new project, it starts with playing around with the data in a **Jupyter notebook**. Once you’ve got a full understanding of what data you’re dealing with and have aligned with the client on what steps to take, one of the outcomes can be to create a predictive ML model\n",
        "\n",
        "You get excited and go back to your notebook to make the best model possible. The model and the results are presented and everyone is happy. The client wants to run the model in their infrastructure to test if they can really create the expected impact. Also, when people can use the model, you get the input necessary to improve it step by step. But how can we quickly do this, given that the client has some complicated infrastructure that you might not be familiar with?\n",
        "\n",
        "For this purpose you need a tool that can fit in their complicated infrastructure, preferably in a language that you’re familiar with. This is where you can use **Flask**\n",
        "\n",
        "> Flask is a micro web framework written in Python. It can create a *REST API* that allows you to send data, and receive a prediction as a response\n",
        "\n",
        "## Create the model\n",
        "\n",
        "Let me show you how this works. For the purpose of demonstration, I will train a simple DecisionTreeClassifier model on an example dataset which can be loaded from the scikit-learn package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4IDqcgoldLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import tree\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmeT5JiTl2VJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wine = load_wine()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3VUIwSsl678",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "123c966a-d357-4b18-9f87-37f54aa1f2b1"
      },
      "source": [
        "df = pd.DataFrame(data=np.c_[wine['data'], wine['target']], columns=wine['feature_names'] + ['target'])\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   alcohol  malic_acid   ash  ...  od280/od315_of_diluted_wines  proline  target\n",
              "0    14.23        1.71  2.43  ...                          3.92   1065.0     0.0\n",
              "1    13.20        1.78  2.14  ...                          3.40   1050.0     0.0\n",
              "2    13.16        2.36  2.67  ...                          3.17   1185.0     0.0\n",
              "3    14.37        1.95  2.50  ...                          3.45   1480.0     0.0\n",
              "4    13.24        2.59  2.87  ...                          2.93    735.0     0.0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K47-nGOimcPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df[:-20]\n",
        "X_test = df[-20:]\n",
        "\n",
        "y_train = X_train.target\n",
        "y_test = X_test.target\n",
        "\n",
        "X_train = X_train.drop('target', 1)\n",
        "X_test = X_test.drop('target', 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkRBwkBMngFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHIH8NyYntA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZewmjN4n2ce",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73975f91-d7d7-4e19-f9bf-6974af75bfc1"
      },
      "source": [
        "print('accuracy_score: %.2f' % accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy_score: 0.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oSbhQf3oGq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import pickle\n",
        "#pickle.dump(clf, open('model/final_prediction.pickle', 'wb'))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU0T4oP9oyo3",
        "colab_type": "text"
      },
      "source": [
        "Once the client is happy with the model you have created, you can save it as pickle file. You can then open this pickle file later and call the function predict to get a prediction for new input data. This is exactly what we will do in *Flask*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnSp5bEdq86z",
        "colab_type": "text"
      },
      "source": [
        "## Run Flask\n",
        " \n",
        "*Flask* runs on a server. This can be in the environment of the client or a different server depending on the client’s requirements. When running python app.py it first loads the created pickle file. Once this is loaded you can start making predictions\n",
        "\n",
        "~~~\n",
        "# code needed for a simple api in Flask\n",
        "\n",
        "from flask import Flask, request, redirect, url_for, flash, jsonify\n",
        "import numpy as np\n",
        "import pickle as p\n",
        "import json\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "@app.route('/api/', methods=['POST'])\n",
        "def makecalc():\n",
        "    data = request.get_json()\n",
        "    prediction = np.array2string(model.predict(data))\n",
        "\n",
        "    return jsonify(prediction)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    modelfile = 'model/final_prediction.pickle'\n",
        "    model = p.load(open(modelfile, 'rb'))\n",
        "    app.run(debug=True, host='0.0.0.0')\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyZhkLWDrZZU",
        "colab_type": "text"
      },
      "source": [
        "## Request predictions\n",
        " \n",
        "Predictions are made by passing a POST JSON request to the created Flask web server which is on port 5000 by default. In app.py this request is received and a prediction is based on the already loaded prediction function of our model. It returns the prediction in JSON format\n",
        "\n",
        "```\n",
        "# test our API\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "url = 'http://0.0.0.0:5000/api/'\n",
        "\n",
        "data = [[14.34, 1.68, 2.7, 25.0, 98.0, 2.8, 1.31, 0.53, 2.7, 13.0, 0.57, 1.96, 660.0]]\n",
        "j_data = json.dumps(data)\n",
        "headers = {'content-type': 'application/json', 'Accept-Charset': 'UTF-8'}\n",
        "r = requests.post(url, data=j_data, headers=headers)\n",
        "print(r, r.text)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAFI-Oegrl-d",
        "colab_type": "text"
      },
      "source": [
        "Now, all you need to do is call the web server with the correct syntax of data points. This corresponds with the format of the original dataset to get this JSON response of your predictions. For example:\n",
        "\n",
        "python request.py -> <Response[200]> '[1.]'\n",
        "\n",
        "For the data we sent we got a prediction of class 1 as output of our model. Actually all you are doing is sending data in an array to an endpoint, which is transformed to JSON format. The endpoint reads the JSON post and transforms it back to the original array\n",
        "\n",
        "With these simple steps you can easily let other people use your machine learning model and quickly make a big impact\n",
        "\n",
        "## Conclusion\n",
        " \n",
        "In this post, I didn’t account for any errors in the data or other exceptions. This article shows how to simply start and learn from the models output, but needs a lot of improvements before it is ready to be put into production. This solution can be made scalable when creating a docker file with the API and hosting it on to Kubernetes so you can balance the load across different machines. But these are all steps to take when going from a proof of concept to a production environment\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1i7fzIUxz-oEs8V4uMdoZCQUl51NMrbVz)\n"
      ]
    }
  ]
}
